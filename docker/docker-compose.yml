services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: dtms-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: dtms-kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    ports:
      - "9092:9092"

  producer:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-producer
    command: ["python", "-m", "streaming.producer"]
    depends_on:
      - kafka
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
    restart: always

  spark-exporter:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-spark-exporter
    command: ["python", "-m", "streaming.spark_stream"]
    depends_on:
      - kafka
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
    ports:
      - "8002:8002"
    volumes:
      - ../../sample_data:/app/sample_data   # NEW: mount for Parquet output
    restart: always

  # ---------------------------
  # Multi-site exporters
  # ---------------------------
  exporter-site-a:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-exporter-site-a
    command: ["python", "-m", "exporter.exporter"]
    environment:
      - SITE_NAME=SITE_A
    # Expose on host for debugging (Codespaces forwards 8000)
    ports:
      - "8000:8000"
    volumes:
      - ../../data:/app/data
    restart: always

  exporter-site-b:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-exporter-site-b
    command: ["python", "-m", "exporter.exporter"]
    environment:
      - SITE_NAME=SITE_B
    # Only inside Docker network; Prometheus can still scrape it
    expose:
      - "8000"
    volumes:
      - ../../data:/app/data
    restart: always

  exporter-site-c:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-exporter-site-c
    command: ["python", "-m", "exporter.exporter"]
    environment:
      - SITE_NAME=SITE_C
    expose:
      - "8000"
    volumes:
      - ../../data:/app/data
    restart: always

  anomaly:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-anomaly-exporter
    command: ["python", "-m", "anomaly.anomaly_exporter"]
    depends_on:
      - exporter-site-a
    ports:
      - "8001:8001"
    volumes:
      - ../../data:/app/data
    restart: always

  prometheus:
    image: prom/prometheus:latest
    container_name: dtms-prometheus
    volumes:
      - ../../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--web.listen-address=0.0.0.0:9090"
    ports:
      - "9090:9090"
    restart: always

  grafana:
    image: grafana/grafana-oss:latest
    container_name: dtms-grafana
    depends_on:
      - prometheus
    ports:
      - "3000:3000"
    restart: always

  api:
    build:
      context: ../..
      dockerfile: infrastructure/docker/Dockerfile
    container_name: dtms-api
    command: ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8003"]
    depends_on:
      - anomaly
    environment:
      - ANOMALY_METRICS_URL=http://anomaly:8001/metrics
    ports:
      - "8003:8003"
    volumes:
      - ../..:/app
    restart: always
